<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>cv on Scholarstree</title>
    <link>https://scholarstree.github.io/tags/cv/</link>
    <description>Recent content in cv on Scholarstree</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Jan 2023 12:00:00 +0530</lastBuildDate><atom:link href="https://scholarstree.github.io/tags/cv/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How-To Notes</title>
      <link>https://scholarstree.github.io/posts/2023-01-05-notes/2023-01-05-notes/</link>
      <pubDate>Wed, 04 Jan 2023 12:00:00 +0530</pubDate>
      
      <guid>https://scholarstree.github.io/posts/2023-01-05-notes/2023-01-05-notes/</guid>
      <description>Notes and sample codes.</description>
      <content:encoded><![CDATA[<h2 id="tensorrt">TensorRT</h2>
<h4 id="converion-from-onnx-to-trt">Converion from ONNX to TRT</h4>
<pre tabindex="0"><code># Windows
trtexec.exe --onnx=INPUT_FILE --saveEngine=OUTPUT_FILE --fp16 --verbose

# Linux
trtexec --onnx=INPUT_FILE --saveEngine=OUTPUT_FILE --fp16 --verbose
</code></pre><p> </p>
<h2 id="docker">Docker</h2>
<h4 id="mount-a-directory-while-initializing-a-container">Mount a directory while initializing a container</h4>
<pre tabindex="0"><code>docker run -it -v DIRECTORY_TO_MOUNT:MOUNT_PATH --gpus all DOCKER_IMAGE
</code></pre><p> </p>
<h2 id="onnx">ONNX</h2>
<h4 id="converion-form-pytorch-to-onnx">Converion form PyTorch to ONNX</h4>
<pre tabindex="0"><code>import torch

# model = DEFINE_MODEL
model.eval() 

dummy_input = torch.randn(1, INPUT_SHAPE, requires_grad=True)  

torch.onnx.export(model,        
        dummy_input,      
        OUTPUT_FILE,      
        export_params=True, 
        opset_version=13,    
        do_constant_folding=True, 
        input_names = [&#39;modelInput&#39;], # the model&#39;s input names
        output_names = [&#39;modelOutput&#39;], # the model&#39;s output names 
        dynamic_axes={&#39;modelInput&#39; : {0 : &#39;batch_size&#39;},    # variable length axes 
                            &#39;modelOutput&#39; : {0 : &#39;batch_size&#39;}}) 
</code></pre><h4 id="modify-inputoutput-dimensions">Modify Input/Output Dimensions</h4>
<pre tabindex="0"><code>import onnx
model = onnx.load(ONNX_INPUT_FILE)

print(model.graph.input)
print(model.graph.output)

# change input dimensions as per model architecture
inputs = model.graph.input
for input in inputs:
    input.type.tensor_type.shape.dim[0].dim_value = 8 # BATCH SIZE
    # input.type.tensor_type.shape.dim[1].dim_value = 416
    # input.type.tensor_type.shape.dim[2].dim_value = 416
    # input.type.tensor_type.shape.dim[3].dim_value = 3

# change output dimensions as per model architecture
outputs = model.graph.output
for output in outputs:
    output.type.tensor_type.shape.dim[0].dim_value = 8 # BATCH SIZE
    # output.type.tensor_type.shape.dim[1].dim_value = 7

onnx.save(model, ONNX_OUTPUT_FILE)
</code></pre><h4 id="fold-constants">Fold constants</h4>
<pre tabindex="0"><code>polygraphy surgeon sanitize --fold-constants INPUT_FILE -o OUTPUT_FILE
</code></pre><p> </p>
<h2 id="python">Python</h2>
<h4 id="make-a-requirementstxt-for-a-project">Make a requirements.txt for a project</h4>
<pre tabindex="0"><code>pip install pipreqs
pipreqs
</code></pre><h4 id="compile-py-to-binary-pyc">Compile .py to binary .pyc</h4>
<pre><code># <i>PYTHON</i>

import argparse
import py_compile

py_compile.compile(INPUT_FILE, cfile=OUTPUT_FILE)
</code></pre>
<h4 id="convert-to-executable">Convert to executable</h4>
<pre tabindex="0"><code>pyinstaller -F FILE_NAME.py --hidden-import=FILE_NAME --hidden-import=OTHER_HIDDEN_IMPORTS
</code></pre><p> </p>
<h2 id="fastapi">FastAPI</h2>
<pre tabindex="0"><code># For FILE_NAME.py containing application name as app
uvicorn FILE_NAME:app --reload --port PORT --workers=NUM_WORKERS
</code></pre><p> </p>
<h2 id="ffmpeg">FFMPEG</h2>
<h4 id="video-file-commands">Video file commands</h4>
<pre tabindex="0"><code># Loop a video 
ffmpeg -stream_loop -1 -t HH:MM:SS -i INPUT_FILE -c copy OUTPUT_FILE
</code></pre><h4 id="rtsp-stream-commands">RTSP stream commands</h4>
<pre tabindex="0"><code># Check if RTSP stream is working
ffprobe -v quiet -print_format json -timeout 5000000 -show_streams RTSP_LINK

# Save stream in one big file
ffmpeg -i RTSP_LINK -nostats -fflags nobuffer -vcodec copy -reset_timestamps 1 -y FILE_NAME.EXTENSION

# Save stream in segments of length SEGMENT_LENGTH seconds
ffmpeg -i RTSP_LINK -nostats -fflags nobuffer -vcodec copy -f segment -segment_time SEGMENT_LENGTH -reset_timestamps 1 -y FILE_NAME%d.EXTENSION

# Create an RTSP stream from a video file
ffmpeg -re -i VIDEO_FILE_PATH -rtsp_transport tcp -c:v copy -an -f rtsp rtsp://localhost:PORT/OPTIONAL_URL_PATH
</code></pre><p> </p>
<h2 id="windows">Windows</h2>
<h4 id="install-a-service-from-an-executable">Install a service from an executable</h4>
<pre tabindex="0"><code>nssm.exe install SERVICE_NAME EXE_PATH
</code></pre>]]></content:encoded>
    </item>
    
    <item>
      <title>t-SNE Visualization of Instagram Posts</title>
      <link>https://scholarstree.github.io/posts/2018-02-03-tsne-visualization-of-instagram-posts/2018-02-03-tsne-visualization-of-instagram-posts/</link>
      <pubDate>Sat, 03 Feb 2018 13:15:56 +0630</pubDate>
      
      <guid>https://scholarstree.github.io/posts/2018-02-03-tsne-visualization-of-instagram-posts/2018-02-03-tsne-visualization-of-instagram-posts/</guid>
      <description>Visualization instagram images in a square grid.</description>
      <content:encoded><![CDATA[<figure class="align-center ">
    <img loading="lazy" src="/2018-02-03-tsne-visualization-of-instagram-posts/tsne_title.jpeg#center"
         alt="tsne_title"/> 
</figure>

<hr>
<p>A year ago, I read <a href="https://karpathy.github.io/2015/10/25/selfie/">Andrej&rsquo;s blog</a> post where he analyzed selfies using Convolutional Neural Networks. I was intrigued by the visualization technique he used which grouped images in such a way that nearby images were similar. In this post, I visualised my own collection of images in a square grid.</p>
<h3 id="steps-involved">Steps Involved</h3>
<p>t-Distributed Stochastic Neighbor Embedding (t-SNE) is a technique for visualizing high dimensional data in 2D or 3D. It defines a cost function between a joint probability distribution,P, in the high-dimensional space and a joint probability distribution, Q, in the low-dimensional space and minimizes that cost function. In this case, we&rsquo;re plotting images but it can be used with all other kinds of data.</p>
<figure class="align-center ">
    <img loading="lazy" src="/2018-02-03-tsne-visualization-of-instagram-posts/tsne_mnist.png#center"
         alt="tsne_mnist"/> <figcaption>
            <p><em>t-SNE visualization of MNIST data.</em></p>
        </figcaption>
</figure>

<figure class="align-center ">
    <img loading="lazy" src="/2018-02-03-tsne-visualization-of-instagram-posts/tsne_mnist_grid.jpeg#center"
         alt="tsne_jpeg"/> <figcaption>
            <p><em>t-SNE visualization of MNIST data in a grid. (Not related to the previous visualization).</em></p>
        </figcaption>
</figure>

<p>The full script can be found <a href="https://github.com/scholarstree/tsne-grid">here</a>. The script requires keras and tensorflow. It is tested with tensorflow (1.4.0) and keras (2.1.1).</p>
<p><strong>Build model</strong>: VGG16 network (without top fc layers) is used and outputs of last conv block are flattened to form a vector.</p>
<p><strong>Load images</strong>: All the images from the source directory are loaded.</p>
<p><strong>Generate high dimensional representations</strong>: A single forward pass through the network generates the high dimensional representations.</p>
<p><strong>Get 2D point locations</strong>: t-SNE implementation of scikit-learn converts these representations to 2D data points.</p>
<p><strong>Distribute 2D representations in a square grid and save images</strong>: Finally, jonker-volgenant algorithm distributes these 2D points into a square grid and we assign every point in the grid a small image.</p>
<figure class="align-center ">
    <img loading="lazy" src="/2018-02-03-tsne-visualization-of-instagram-posts/tsne_rand.jpeg#center"
         alt="tsne_rand"/> <figcaption>
            <p><em>t-SNE visualization of some random images in a grid.</em></p>
        </figcaption>
</figure>

<h3 id="system-details">System Details</h3>
<p>HP Pavilion<br>
4 GB RAM<br>
Nvidia GeForce GT 740M</p>
<h3 id="__references__"><strong>References</strong></h3>
<ol>
<li>L.J.P. van der Maaten and G.E. Hinton. Visualizing High-Dimensional Data Using t-SNE. Journal of Machine Learning Research 9(Nov):2579–2605, 2008.<a href="https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf">[PDF]</a><a href="https://lvdmaaten.github.io/publications/misc/Supplement_JMLR_2008.pdf">[Supplemental material]</a><a href="https://www.youtube.com/watch?v=RJVL80Gg3lA&amp;list=UUtXKDgv1AVoG88PLl8nGXmw">[Talk]</a><a href="https://lvdmaaten.github.io/tsne/">[Code]</a></li>
</ol>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
